---
title: "Assignment 5"
output: html_notebook
---

Loading required packages
```{r}
library(tidyverse)
library(psych)
library(magrittr)
library(vcd)
library(MASS)
library(caret)
library(readr)
library(readxl)
```
Question 1a:
Step 1. Open "iris" data set 
```{r}
iris <- iris
```
Step 2. Summary statistics for all variables
```{r}
iris %>%  
    describe     
table(iris$Species)
```
From table 1 we can determine that there were 150 flower observations, and no missing data. Table 2 indicates that there were 50 observations of each of the 3 species: setosa, versicolor, and virginica. This is a factor variable, thus setosa = 1, versicolor = 2, and virginica = 3 in the code. Skewness and kurtosis statistics are acceptable for all continuous variables, suggesting normal distribution. An examination of minimum and maximum variables do not indicate values that are likely to be false (due to an impossible size)

Step 3. Check distribution of continuous variables by Species, to establish multivariate normality (IVs must be normally distributed at each level of the grouping variable, i.e.: species)
```{r}
ggplot(data = iris, mapping = aes(x = Sepal.Length))+
  geom_histogram(bins = 20)+
  facet_wrap(~Species, nrow =3)
ggplot(data = iris, mapping = aes(x = Sepal.Width))+
  geom_histogram(bins = 20)+
  facet_wrap(~Species, nrow = 3)
ggplot(data = iris, mapping = aes(x = Petal.Length))+
  geom_histogram(bins = 20)+
  facet_wrap(~Species, nrow = 3)
ggplot(data = iris, mapping = aes(x = Petal.Width))+
  geom_histogram(bins = 20)+
  facet_wrap(~Species, nrow = 3)
```
All variables look fairly normally distributed within each species. Linear discriminant analysis is also robust to slight violations of multivariate normality. 
Each of the 150 obsertvations is of a seperate flower, thus cases are independent.

Step 4. Check grouped distributions with summary stats, where skewness and kurtosis are reported by group. 
```{r}
describeBy(iris, group = iris$Species)

```
Table 2 = setosa, table 3 = versicolor, and table 4 = virginica
All skewness and kurtosis values are acceptable, suggesting normal distribution of each variable for each species.
Setosa have the lowest mean sepal length (m = 5.01, SD = 0.35), followed by versicolor (m = 5.94, SD = 0.52), and then virginica (m = 6.59, SD = 0.64).
Setosa have the highest mean sepal width(m = 3.43, SD = 0.38), followed by virginica (m = 2.97, SD = 0.32), and then versicolor (m = 2.77, SD = 0.31), although the latter two have very similar means.
This creates the impression that setosa have shorter, broader sepals, versicolor have longer, narrower sepals, and virginica have even longer sepals that are of similar bredth to versicolor sepals.
Setosa have the lowest mean petal length (m = 1.46, SD = 0.17), followed by versicolor (m = 4.26, SD = 0.47), and then virginica (m = 5.55, SD = 0.55)
Setosa also have the lowest mean petal width (m = 0.25, SD = 11), followed by versicolor (m = 1.33, SD = 0.20), and virginica (m = 2.03, SD = 0.27)
So the setosa have the smallest petals (shortest and narrowest), followed by versicolor, and then virginica.
In general, the flowers tend to ascend in size: setosa, versicolor, virginica (respectively). But whilst the petals get longer and broader, the sepals get longer and thinner.

Step 5. check the relationship between each aspect of flower measurement and species
```{r}
ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width, color = Species))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)
ggplot(data = iris, mapping = aes(x = Petal.Length, y = Petal.Width, color = Species))+
  geom_point()+
  geom_smooth(method = "lm", se = FALSE)

```
Graph 1 depicts the sepals in terms of length and width by species.
As suggested by the summary, Setosa have distinctive short, broad petals. Versiocolor and Virginica have some overlap in the appearance of their sepals. Versicolor sepals are typically narrower than Setosa sepals, although there is a fair amount if overlap in sepal length. Virginica tend to have longer sepals than Setosa do, although there is a fair amount of overlap in sepal width. All sepals get wider as they get longer.
Graph 2 depicts the petals in terms of length and width by species. The petal characteristics for each species are much more distinct than the sepal characteristics. As suggested by the summary statistics, petal size (length and width) increases across the species in the order: setosa, versicolor, virginica.

Step 6. Due to the seemingly interactive nature of the two measurements for each part of the plant, it may be useful to see how the interaction of length and width for the sepals and petals correlate with species
```{r}
ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length*Sepal.Width))+
  geom_jitter(height = 0, width = 0.25)+
  geom_smooth(se = FALSE)
ggplot(data = iris, mapping = aes(x = Species, y = Petal.Length*Petal.Width))+
  geom_jitter(height = 0, width = 0.25)+
  geom_smooth(se = FALSE)
         
```
Whilst the sepal size (Graph 1) does not produce a clear pattern, petal size (Graph 2) clearly depitcs the ascending size pattern noted earlier.

Question 1b
Run a linear discriminant analysis to predict species, using the 4 variables in the data
```{r}
ldamodel1 <-lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
ldamodel1

```
The prior probabilities of the groups confirm an equal number of observations were conducted for each species (one third of the total observations)

Question 1c:
USe confusion matrix to compute success rate
```{r}

ldamodel1predict <- predict(ldamodel1)
confusionMatrix(ldamodel1predict$class, iris$Species)
```
The accuracy of this model is 0.98, meaning that this model can predict the species correctly from the plant part ratios (the variables) 98% of the time. The no information rate is 0.3333, meaning that with no information, the species would be correctly identified 33% of the time (by chance). Adding these 4 predictors improves the model by 65%. The 4 variable model is very good (and highly significant, p < 0.001):
- it classified all cases of setosa correctly (as was suggested by the exploratory plots - where setosa was the most distinct in terms of both sepals and petals)
- it only classified 2 cases of versicolor as virginica, and one case of virginica as versicolor (which could be expected, as there was an overlap in the sepal characteristics of these 2 species)

147/150 observations were successfully classified according to species
Sensitivity and specificity values were >= 0.98 for all 3 species

QUestion 1d. 
Use the plotting methods built into LDA in MASS to explore the adequacy of the classification.
What do they tell you?

Plot histogram with density plot overlay for each variable. All variables are multivariate normally distributed, meaning that each variable has a normal distribution for each species of iris. 
```{r}
ldahist(iris$Sepal.Length, iris$Species, type = "both")
ldahist(iris$Sepal.Width, iris$Species, type = "both")
ldahist(iris$Petal.Length, iris$Species, type = "both")
ldahist(iris$Petal.Width, iris$Species, type = "histogram")
```
Question 1e:
Use cross validation in lda and compare classification rate success
Start by creating a vector of 113 random numbers ranging from 1 to 150 (113/150 observations is roughly 75%)
Next, randomly select a subset of 113 cases from the data set to be analysed as a training sample
```{r}
random113 <- sample(1:150, 113, replace = FALSE)
ldamodel2 <-lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris, subset = random113)
ldamodel2
ldamodel2predict <- predict(ldamodel2)
confusionMatrix(ldamodel2predict$class, iris$Species[random113])

```
I'm not sure how to compare this to a test set. I will therefore use traditional training and test sets

```{r}
# Build the training and test data sets
set.seed(2)
iristraindata <- sample_frac(iris, 0.75)
iristestdata  <- dplyr::setdiff(iris, iristraindata)

# Build the lda model on the training data set
ldamodeltrain <- lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iristraindata)

# Generate an LDA prediction object of traindata
ldamodeltrainpred <- predict(ldamodeltrain)

# Generate a confusion matrix for training set
confusionMatrix(as.factor(ldamodeltrainpred$class), as.factor(iristraindata$Species), 
                positive = c("1"))

# Generate an LDA prediction object of testdata
ldamodeltestpred <- predict(ldamodeltrain,
                            newdata = iristestdata)

# Generate a confusion matrix for test set
confusionMatrix(as.factor(ldamodeltestpred$class), as.factor(iristestdata$Species), 
                positive = c("1"))

```
THe train data (on which we built the model) has an accuracy of 0.9911, thus in about 99% of cases the model correctly predicts iris species.
The test data has an accuracy of 0.9474, thus in about 95% of cases the model correctly predicts iris species. A slight drop in accuracy is to be expected, but the model is still very good and highly significant (p < 0.001)


Question 1f. 
Repeat a quadratic discriminant analysis for the model, and include accuracy rate from confusion matrix
```{r}
qdamodel1 <-qda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
qdamodel1
qdamodel1predict <- predict(qdamodel1)
confusionMatrix(qdamodel1predict$class, iris$Species)
```
This quadratic discriminant analysis has the same high accuracy (0.98) as the linear discriminant analysis, and it has the same significance. THis confirms that the model is linear and not quadratic, as adding the option for a quadratic distribution did not improve the model.
_____________________________________________________________________
Question 2:
Load data set titanic3.xls
```{r}
titanic<- read_excel("../data/titanic3.xls")
```

Question 2a: 
split data into training and test sets

```{r}
# Build the training and test data sets
set.seed(2)
titanictraindata <- sample_frac(titanic, 0.75)
titanictestdata  <- dplyr::setdiff(titanic, titanictraindata)

```
VARIABLE DESCRIPTIONS:
pclass Passenger Class
 (1 = 1st; 2 = 2nd; 3 = 3rd)
survival Survival
 (0 = No; 1 = Yes)
sex Sex
age Age
sibsp Number of Siblings/Spouses Aboard
parch Number of Parents/Children Aboard
fare Passenger Fare

```{r}
titanictraindata$survived_fact <- as.factor(titanictraindata$survived)


qdatitanicmodel1 <- qda(survived_fact ~ pclass + as.factor(sex) + sibsp + parch, data = titanictraindata)
qdatitanicmodel1

qdatitanicmodel1predict <- predict(qdatitanicmodel1)
confusionMatrix(qdatitanicmodel1predict$class, titanictraindata$survived_fact)

```
This model has an accuracy rate of 78%

Question 2b:

Test your model on the test set by computing and comparing MSE train and MSE test. (5)
c. Re-run the analysis above (i.e. split the dataset into training and test sets, use the model
you developed in a) and b) to compute MSE of the model as applied to the test set only),
1000 times (inside a loop). Gather the accuracy rates and plot them as a histogram.
What do you conclude? (10)
d. Conduct LOOCV using the cv.glm function (in package boot). Note the cost function that
you need to use. How does the result compare to what you found in b)? (10)
e. Conduct 2 fold, 5 fold, and 10 fold cross validation using the cv.glm function. Set the
random seed to 199 so that results are replicable. How do the results compare to what
you found in c), b), and a)? (10)
